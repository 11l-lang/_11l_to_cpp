V css = ‘<style>
span.keyword {color: #0000FF; font-weight: bold;}
span.identifier {color: #00009F;}
span.string-literal {color: #800000;}
span.numeric-literal {color: #008000;}
span.constant {color: #008000;}
span.comment {color: #808080;}
</style>’

V cat_to_class_python = [
   python_to_11l:tokenizer:Token.Category.NAME                  = ‘identifier’,
   python_to_11l:tokenizer:Token.Category.KEYWORD               = ‘keyword’,
   python_to_11l:tokenizer:Token.Category.CONSTANT              = ‘constant’,
   python_to_11l:tokenizer:Token.Category.OPERATOR_OR_DELIMITER = ‘’,
   python_to_11l:tokenizer:Token.Category.NUMERIC_LITERAL       = ‘numeric-literal’,
   python_to_11l:tokenizer:Token.Category.STRING_LITERAL        = ‘string-literal’,
   python_to_11l:tokenizer:Token.Category.FSTRING               = ‘string-literal’,
   python_to_11l:tokenizer:Token.Category.FSTRING_END           = ‘string-literal’,
   python_to_11l:tokenizer:Token.Category.INDENT                = ‘’,
   python_to_11l:tokenizer:Token.Category.DEDENT                = ‘’,
   python_to_11l:tokenizer:Token.Category.STATEMENT_SEPARATOR   = ‘’
]

V cat_to_class_11l = [
   _11l_to_cpp:tokenizer:Token.Category.NAME                = ‘identifier’,
   _11l_to_cpp:tokenizer:Token.Category.KEYWORD             = ‘keyword’,
   _11l_to_cpp:tokenizer:Token.Category.CONSTANT            = ‘constant’,
   _11l_to_cpp:tokenizer:Token.Category.DELIMITER           = ‘’,
   _11l_to_cpp:tokenizer:Token.Category.OPERATOR            = ‘’,
   _11l_to_cpp:tokenizer:Token.Category.NUMERIC_LITERAL     = ‘numeric-literal’,
   _11l_to_cpp:tokenizer:Token.Category.STRING_LITERAL      = ‘string-literal’,
   _11l_to_cpp:tokenizer:Token.Category.FSTRING             = ‘string-literal’,
   _11l_to_cpp:tokenizer:Token.Category.FSTRING_END         = ‘string-literal’,
   _11l_to_cpp:tokenizer:Token.Category.STRING_CONCATENATOR = ‘’,
   _11l_to_cpp:tokenizer:Token.Category.SCOPE_BEGIN         = ‘’,
   _11l_to_cpp:tokenizer:Token.Category.SCOPE_END           = ‘’,
   _11l_to_cpp:tokenizer:Token.Category.STATEMENT_SEPARATOR = ‘’
]

F is_lang_supported(lang)
   R lang C (‘11l’, ‘Python’)

T Error
   String message
   Int pos
   F (message, pos)
      .message = message
      .pos = pos

F highlight(lang, source)
   V writepos = 0
   [(Int, Int)] comments
   V cur_comment = 0
   V res = ‘’

   F html_escape(s)
      R s.replace(‘&’, ‘&amp;’).replace(‘<’, ‘&lt;’)

   I lang == ‘Python’
      X.try
         L(token) python_to_11l:tokenizer:tokenize(source, comments' &comments) [+] [python_to_11l:tokenizer:Token(source.len, source.len, python_to_11l:tokenizer:Token.Category.STATEMENT_SEPARATOR)]
            L cur_comment < comments.len & comments[cur_comment][0] < token.start
               res ‘’= html_escape(source[writepos .< comments[cur_comment][0]])
               writepos = comments[cur_comment][1]
               res ‘’= ‘<span class="comment">’html_escape(source[comments[cur_comment][0] .< comments[cur_comment][1]])‘</span>’
               cur_comment++
            res ‘’= html_escape(source[writepos .< token.start])
            writepos = token.end
            V css_class = :cat_to_class_python[token.category]
            I css_class != ‘’
               res ‘’= ‘<span class="’css_class‘">’html_escape(token.value(source))‘</span>’
            E
               res ‘’= html_escape(token.value(source))

      X.catch python_to_11l:tokenizer:Error e
         X.throw Error(e.message, e.pos)
   E
      assert(lang == ‘11l’)
      X.try
         V inside_fstring = 0

         L(token) _11l_to_cpp:tokenizer:tokenize(source, comments' &comments) [+] [_11l_to_cpp:tokenizer:Token(source.len, source.len, _11l_to_cpp:tokenizer:Token.Category.STATEMENT_SEPARATOR)]
            L cur_comment < comments.len & comments[cur_comment][0] < token.start
               res ‘’= html_escape(source[writepos .< comments[cur_comment][0]])
               writepos = comments[cur_comment][1]
               res ‘’= ‘<span class="comment">’html_escape(source[comments[cur_comment][0] .< comments[cur_comment][1]])‘</span>’
               cur_comment++
            res ‘’= html_escape(source[writepos .< token.start])
            writepos = token.end

            V tokstr = html_escape(token.value(source))
            String css_class
            I (token.category == NAME & token.value(source).rtrim([Char](‘&?’)) C (‘V’, ‘П’, ‘var’, ‘пер’)) | (token.category == OPERATOR & tokstr C (‘C’, ‘С’, ‘in’, ‘св’, ‘!C’, ‘!С’, ‘!in’, ‘!св’)) | tokstr.split(‘.’)[0] C _11l_to_cpp:tokenizer:keywords
               css_class = ‘keyword’
            E
               css_class = :cat_to_class_11l[token.category]

            I token.category == FSTRING
               inside_fstring++
            E I token.category == FSTRING_END
               inside_fstring--

            I css_class != ‘’
               I token.category == STRING_LITERAL & inside_fstring == 0
                  I tokstr[0] == ‘'’
                     V apos = 1
                     L tokstr[apos] == ‘'’
                        apos++
                     assert(tokstr[0 .< apos * 2 + 1] == (‘'’ * apos)‘’("‘" * apos)"‘")
                     tokstr = ‘<span style="opacity: 0.25">’tokstr[0 .< apos * 2]‘</span>’tokstr[apos * 2 ..]
                  I tokstr.last == ‘'’
                     V apos = 1
                     L tokstr[(len)-(apos + 1)] == ‘'’
                        apos++
                     assert(tokstr[(len)-(apos * 2 + 1) ..] == "’"("’" * apos)‘’(‘'’ * apos))
                     tokstr = tokstr[0 .< (len)-(apos * 2)]‘<span style="opacity: 0.25">’tokstr[(len)-(apos * 2) ..]‘</span>’
               res ‘’= ‘<span class="’css_class‘">’tokstr‘</span>’
            E
               res ‘’= tokstr

      X.catch _11l_to_cpp:tokenizer:Error e
         X.throw Error(e.message, e.pos)

   R res
